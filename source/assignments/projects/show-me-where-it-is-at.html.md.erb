---
title: Show Me Where It's At
description: |
  Our first project: given a user-specified location, traverse a public dataset with geographic information, and deliver the user to a webpage showing the closest records/incidents.
due_date: 2016-02-25
points: 100
summary: |
  Write a program that shows the user where they are in relation to incidents from a geocoded dataset, using satellite map imagery and other data.
kind: Project
components:
  - title: Write a command-line interface
    slug: write-cli
    points: 2
  - title: Geocode a user-supplied address using a geocoding API
    slug: geocode-user
    points: 3
  - title: Collect and curate a dataset that contains geographic data
    slug: curate-dataset
    points: 5
  - title: Find nearest data items to a  given point
    points: 2
  - title: Access satellite imagery 
    slug: get-satellite
    points: 2
  - title: Create a HTML report
    slug: html-report
    points: 4
---


# Deliverables

## Things _not_ to do

This project is not meant to be a test of software-engineering, but just to push you to create something more complicated than the homework assignments, so you get the feel of how things are integrated. A lot of parts will be provided to you. And for the most part, I'm not grading on style, either in code or output.

Given those vague goals, it's easier just to state what __will__ end up docking you in points:

###### 1. Your project repo contains your Mapzen credentials

You will have to include a geocoder function. But that doesn't mean you have to include _your Mapzen API credentials_. If you create a new text file and name it correctly -- e.g. `creds_mapzen.txt` -- and store your key in there, to be read by your main program, then you're good to go.

But if you paste your API key -- i.e. `"search-xxyyzz"` -- as a _literal_ text string anywhere in your code base -- you've basically given up your password to anyone who downloads your program. That's bad. And if you did that, it shows that you probably don't yet grasp the concept of opening a file, reading its contents as text, and using it in a program, which is something you've been doing for each assignment up to this point.


###### 2. Your `publish` command includes a picture of Nicolas Cage

This project requires you to produce a webpage for the user.

But it's not a web design project so I'll have a few examples for you to copy from and tailor to your liking. They will include pictures of Nicolas Cage: 

If your command contain






## Project folder

Create a new folder in your __compciv-2016__ repo:

<pre class="filetree">
    compciv-2016
    └── projects
        └── show-me-where           
</pre>

All of your files for this project will be in the projects/show-me-where file directory.

At a minimum, this is what your project folder should contain:

<pre class="filetree">
    compciv-2016
    └── projects
        └── show-me-where           
            └── README.md
            └── woz.py 
</pre>

And this is what I should be able to do to run your program from my system shell:

~~~sh
$ python woz.py
~~~

## Minimum functionality

What it does after that can vary quite a bit...but here is the general design that I want to see:

When I run your `woz.py` script, it should ask me what I want to do. Your script should have a response to these commands:

### Little helper commands

The following commands are required just to make sure you can get small parts of the application working. For example, can you make a program that says "hello" to the user.

There are also commands such as `geocode` and `filtrate` that aren't really meant for the user to call directly, but are useful to have, on their own, so you can test them out without running the "main" commands, which are __report__ and __publish__:


- __hello__: Have the program ask my name, then say something like `"Hello, [whatever my name happens to be when I check your program]"`
- __help__: Prints all the docstrings for each of the functions that comprise your program, e.g. `geocode()`, `wrangle()` (here's [Python's documentation on what a docstring is](https://www.python.org/dev/peps/pep-0257/))
- __bootstrap__: Creates any folders you need to stash data or other temporary files into. Also, downloads the original dataset that you're working with.
- __wrangle__: Performs any preparation of the raw original dataset that's needed...which might be nothing. But if it does have to do something, this script should save this "wrangled" data into a new file, separate from the original data. Mostly, this step exists for you to produce a form of the data that is easier for the rest of your program to work with. If your data requires __geolocation__, this is where you want to do it (i.e. if you have to add latitude/longitude columns)
- __geocode__: Asks me for a location, then prints a JSON-formatted string that contains [Mapzen Search-powered geolocation data based on what I entered](https://mapzen.com/projects/search/).
- __filtrate__: This asks me for a __longitude__ and a __latitude__. It then uses these numbers to __sort__ your "wrangled" dataset, then _filter_ (I'm requiring the function to be called __filtrate__ just so you don't accidentally overwrite Python's built-in `filter()` function) it to find the 5 (or whatever) nearest records, by geographical distance. Note: for the most part, I'll just give you the code to most effectively do this. But you should still at least remember how to sort data objects.

### Main user-facing commands

These are the commands that wrap up functionality in the previous commands and actually produce something interesting. For example, they both will call your `geocode()` function and translate a user-provided location into geocoordinates. Then they will use `filtrate()` to get the nearest records to the user.

Basically, these commands are concerned with making your data __presentable and relevant__ to the user:

- __report__: This command should ask the user for their location, e.g. `"Stanford, CA"` and use that to print a plain-text, but human-readable list of relevant data (i.e. nearest records) from your data.

- __publish__: This command should, again, ask the user for their location, find the most relevant records based on location...but then send the user to a __webpage__, where the data is even more human-readable than it was in __report__.




## Detailed implementation

(Note: I'm trying to have instructions here while simultaneously having them on the live example and tutorial...and I've failed at completing that duplication here at the moment. But the description of the __bootstrap()__ function is relevant)

### A bootstrap() function

There should be a __bootstrap()__ function that, when run, will do these things:

###### 1. Create a tempdata/ sub-directory

Our good friend the `tempdata/` directory will be joining us as in previous assignments:

<pre class="filetree">
    compciv-2016
    └── projects
        └── show-me-where           
            └── README.md
            └── woz.py 
            └── tempdata/
</pre>

###### 2. Download the data for your project from its original source

Your data should have some place that it can be downloaded from the source. For example, if I were doing earthquakes, my source file would be at this URL:

<%= link_to_url_alone "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_month.csv" %>

And my `bootstrap()` function would download and save it somewhere in my `tempdata` subdirectory. I might even make a special subdirectory for it (you can do what you like):

<pre class="filetree">
    compciv-2016
    └── projects
        └── show-me-where           
            └── README.md
            └── woz.py 
            └── tempdata
                └── original
                    └── earthquakes.csv
</pre>









(That's it for now. Check out the demo for an example, and make sure it can run on your system: [https://github.com/compciv/show-me-earthquakes](https://github.com/compciv/show-me-earthquakes))


-------------



<a id="mark-data-readme"></a>

## Find a dataset, write a README (2016-02-04)

Part of creating a good project is just documenting what you have.

First, find a dataset that meets these characteristics:

- At least 100 records
- Contains either geocoordinate fields (e.g. latitude, longitude) or fields that _can_ be geocodable, e.g. street address, city, state, zip.
- Is interesting, even if just to you.

Then, create a `README.md` file in your project folder. 

Create a heading named "About the Dataset", under which you will describe the characteristics of the data (as described below).

Visit the [some-student repo to see an example of the README.md file and the project folder](https://github.com/some-student/compciv-2016/blob/master/projects/show-me-where/).

### Where to put the README.md file

In your project folder, create a file named `README.md`:

<pre class="filetree">
    compciv-2016
    └── projects
        └── show-me-where
            └── README.md 
</pre>

### What it contains

In the __README.md__ file, create the heading, __"About the dataset"__

#### 1. A short paragraph describing the data

Write a few sentences describing to a general audience what the dataset contains, where it comes from, why you find it interesting, etc.

#### 2. A listing of basic facts about the dataset

- The name of the agency or organization that originated the data. You may have to Google around for this. And you may find that there's a _better_ or more direct source for the data.
- A URL to the __landing page__ where you found the data, i.e. where the data file is linked to.
- If applicable: A __direct__ URL to the data file itself, i.e. if I click it, the data just downloads. 
- The __format__ of the data, e.g. is it a JSON, CSV, or other kind of delimited text file?
- How many __rows__ are in the data file


#### 3. A description of each of the fields

This is a listing of all the columns/attributes of each record, with a sentence briefly describing what the column contains and the __data type__, e.g. text, integer, float, date, true/false (i.e. boolean). Note that this doesn't necessarily map to Python data types. I just want you to know that _you_ know what your data contains.

#### 4. Describe the anticipated "data wrangling"

It's quite rare that the data you download will be exactly as you need it. Describe, in general terms, what changes/edits/cleaning you anticipate that you might have to do (we'll figure out how to do it programmatically later).

Examples:

- I plan to trim the dataset to show only the last 3 months worth of records.
- The dataset only had a `coordinates` field, in which latitude and longitude are in a single string, e.g. "(-42.9138223, 106.9202332)". I will have to split that field up into two separate numbers.
- My dataset includes too many boring categories. I plan to limit the dataset to include records in which the `subcategory` column is equal to `"ROBBERIES"` 

#### Use Markdown

Write this README.md file [using the __Markdown syntax__](https://help.github.com/articles/basic-writing-and-formatting-syntax/), which is a handy plaintext format that Github (and many, many other services) know how to render into attractive HTML.

For example, the following Markdown:

~~~
My *name* is **Dan** and I say [potatoe](http://www.washingtonpost.com/wp-srv/politics/special/clinton/frenzy/quayle3.htm)

- And
- This is a
- bulleted list
~~~

Results in this HTML rendering:

~~~html
<p>
  My <em>name</em> is <strong>Dan</strong> and I say <a href="http://www.washingtonpost.com/wp-srv/politics/special/clinton/frenzy/quayle3.htm">potatoe</a>
</p>

<ul>
  <li>And</li>
  <li>This is a</li>
  <li>bulleted list</li>
</ul>
~~~

Which looks like:

------

My *name* is **Dan** and I say [potatoe](http://www.washingtonpost.com/wp-srv/politics/special/clinton/frenzy/quayle3.htm)

- And
- This is a
- bulleted list

------

You can see more examples in [Github's basic Markdown syntax guide](https://help.github.com/articles/basic-writing-and-formatting-syntax/). I'm making this a requirement because using Markdown is a genuinely useful skill; also, it's very easy to learn, which is why it was created in the first place.


- [Here's the example report](https://github.com/some-student/compciv-2016/tree/master/projects/show-me-where), when you visit the project folder page on Github.

- [Here's the raw Markdown source of that file](https://raw.githubusercontent.com/some-student/compciv-2016/master/projects/show-me-where/README.md)




# Requirements


## A. Find a geolocated/geolocatable dataset

- Find, collect, curate, and clean a dataset of _at least_ 100 records.
- This dataset must have geocoordinates -- i.e. latitude and longitude -- or address information that can be sent to a geocoding service.

## B. Write a user-facing program

Write a program with these features:

### 1. Geocodes a user's address

- Takes in free-form text input from the user.
- Given an address text string, uses a geocoding service to find the corresponding latitude and longitude coordinates.

### 2. Finds n records in dataset, sorted by proximity to user

- From the dataset collected in the previous requirement, find _n_ records (at least 3) in order of shortest distance to user

### 3. Create a HTML report

Create a webpage and send the user to it (via the [webbrowser](https://docs.python.org/3/library/webbrowser.html) module), with these features:

1. Map imagery showing where the user is in relation to the _n_ closest incidents.
2. A table/list of the _n_ closest incidents, with relevant data fields.
3. The webpage can be created locally, i.e. as a text file on the user's hard drive.

__For requirement 2__: For example, if your dataset consists of the last year's worth of [auto theft in San Francisco](https://data.sfgov.org/Public-Safety/SFPD-Incidents-from-1-January-2003/tmnf-yvry), besides listing the location and distance from user, your data table should probably also list:

- Date of the incident
- Specific subcategory of auto theft
- Whether a suspect was arrested


The design or aesthetic quality of the webpage is not being graded. But obviously, you should try to make it look nice if you have time.

# Example datasets
 
Examples of public datasets with geospatial data and/or physical addresses:

- [Police shootings via the Fatal Encounters Project](https://docs.google.com/spreadsheet/ccc?key=0Aul9Ys3cd80fdHNuRG5VeWpfbnU4eVdIWTU3Q0xwSEE&usp=sharing)
- [Police shootings via The Guardian](http://www.theguardian.com/us-news/ng-interactive/2015/jun/01/about-the-counted)
- [USGS Earthquakes Catalog](http://earthquake.usgs.gov/fdsnws/event/1/)
- [USGS National Hydrography Dataset](http://nhd.usgs.gov/data.html) - Probably requires a lot of domain knowledge to easily use...
- [OSHA Chemical Exposure Health Data](https://www.osha.gov/opengov/healthsamples.html)
- [Hospital complications](https://data.medicare.gov/Hospital-Compare/Complications-Hospital/632h-zaca)
- [School locations with demographics, nationwide](http://nces.ed.gov/ccd/pubschuniv.asp)
- [Clinical Trials](https://clinicaltrials.gov/ct2/resources/download)
- [UK Police incident reports and stop-and-frisks](https://data.police.uk/data/)
+ [NYPD Stop-and-Frisks](http://www.nyc.gov/html/nypd/html/analysis_and_planning/stop_question_and_frisk_report.shtml)
+ [NYC MTA subway stations and bus stop locations](http://web.mta.info/developers/developer-data-terms.html#data)
- [In-n-Out Burger Locations](http://www.in-n-out.com/locations) - requires web scraping and HTML parsing
- [EPA Enforcement Data](https://echo.epa.gov/tools/data-downloads#downloads)
- [National Park Boundaries](https://catalog.data.gov/dataset/national-park-boundariesf0a4c)
### Socrata-powered data portals

You can try [Open Data Network](http://www.opendatanetwork.com/) to do a search across all Socrata sites.

Here are examples of Socrata data portals for various cities and jurisdictions, along with examples of geolocatable datasets:

- [San Francisco Open Data Portal: Datasets](https://data.sfgov.org/data?category=&dept=&search=&type=datasets)
  + [SFPD Incidents](https://data.sfgov.org/Public-Safety/SFPD-Incidents-from-1-January-2003/tmnf-yvry)
  + [Restaurant inspections](https://data.sfgov.org/Health-and-Social-Services/Restaurant-Scores/stya-26eb)
  + [311 Calls](https://data.sfgov.org/City-Infrastructure/Case-Data-from-San-Francisco-311-SF311-/vw6y-z8j6) - e.g. pot holes, graffiti, human waste
  + [Street Tree List](https://data.sfgov.org/City-Infrastructure/Street-Tree-List/tkzw-k3nq)
  + [Eviction Notices](https://data.sfgov.org/Housing-and-Buildings/Eviction-Notices/5cei-gny5)
  + [Food truck schedules](https://data.sfgov.org/Economy-and-Community/Mobile-Food-Schedule/jjew-r69b)
  + [Disabled Parking](https://data.sfgov.org/Transportation/Disabled-Parking/wc6f-brai) requires a bit of text string cleaning to get latitude/longitude fields
  + [Film Locations in San Francisco](https://data.sfgov.org/Culture-and-Recreation/Film-Locations-in-San-Francisco/yitu-d5am) - a fun dataset, but requires geocoding and probably a significant amount of manual data-cleaning and agggregation.

- [New York City Open Data Portal: Datasets](https://nycopendata.socrata.com/data?browseSearch=&scope=&agency=&cat=&type=datasets)
  + [Restaurant inspections](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j)
  + [311 Calls](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9)
  + [Major Felony Incidents](https://data.cityofnewyork.us/Public-Safety/NYPD-7-Major-Felony-Incidents/hyij-8hr7)
  + [Motor Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95)
  + [FDNY Firehouses](https://data.cityofnewyork.us/Public-Safety/FDNY-Firehouse-Listing/hc8x-tcnd)
  + [Farmers Markets](https://data.cityofnewyork.us/Health/New-York-City-Farmers-Markets/j8gx-kc43)
  + [Buildings with "Cool Roofs"](https://data.cityofnewyork.us/Environment/NYC-Cool-Roofs-Buildings/uuxn-wzxe)


- [Dallas Open Data Portal: Datasets](https://www.dallasopendata.com/browse?limitTo=datasets&utf8=%E2%9C%93)
  + [Dallas PD active calls](https://www.dallasopendata.com/dataset/Dallas-Police-Active-Calls/9fxf-t2tr)
  + [Dallas PD reported crime incidents](https://www.dallasopendata.com/Police/Dallas-Police-Public-Data-RMS-Incidents/tbnj-w5hb)
  + [Dallas PD Officer Involved Shootings](https://www.dallasopendata.com/Police/Dallas-Police-Public-Data-Officer-Involved-Shootin/4gmt-jyx2)
  + [Code Violations](https://www.dallasopendata.com/dataset/Code-Violations/x9pz-kdq9)
  
- [Chicago Open Data Portal](https://data.cityofchicago.org/browse?limitTo=datasets&utf8=%E2%9C%93)
  + [Reported crime incidents](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2)
  + [Building permits](https://data.cityofchicago.org/Buildings/Building-Permits/ydr8-5enu)

- [Baltimore Open Data Portal: Datasets](https://data.baltimorecity.gov/browse?limitTo=datasets&utf8=%E2%9C%93)
- [Iowa Open Data Portal: Datasets](https://data.iowa.gov/browse?&limitTo=datasets&utf8=✓)
- [Los Angeles Open Data Portal: Datasets](https://data.lacity.org/browse?limitTo=datasets&utf8=%E2%9C%93)
- [Maryland Open Data Portal: Datasets](https://data.maryland.gov/browse?limitTo=datasets&utf8=%E2%9C%93)
- [Oakland Open Data Portal: Datasets](https://data.oaklandnet.com/browse?limitTo=datasets&utf8=%E2%9C%93)
- [Santa Monica Open Data Portal: Datasets](https://data.smgov.net/browse?limitTo=datasets)
- [Seattle Open Data Portal: Datasets](https://data.seattle.gov/browse?limitTo=datasets&sortBy=most_accessed&sortPeriod=week&utf8=%E2%9C%93)
